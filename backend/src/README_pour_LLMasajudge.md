# Agent 3 : LLM Judge - √âvaluation de Qualit√© (Anthropic Claude)

Agent 3 √©value la qualit√© des analyses produites par Agent 1B (Pertinence Checker) et Agent 2 (Risk Analyzer) selon 8 crit√®res avec scoring pond√©r√© adaptatif.

**Version** : Anthropic Claude API (SDK natif)

---

## üìä Fonctionnalit√©s

### 1. √âvaluation Multi-Crit√®res

**Pour Pertinence Checker (4 crit√®res)** :

- Source Relevance
- Company Data Alignment
- Logical Coherence
- Traceability

**Pour Risk Analyzer (8 crit√®res)** :

- Source Relevance
- Company Data Alignment
- Logical Coherence
- Completeness
- Recommendation Appropriateness
- Traceability
- Strategic Alignment (nouveau)
- Actionability Timeline (nouveau)

### 2. Scoring Pond√©r√© par Type de Risque

Les crit√®res ont des poids diff√©rents selon le type d'√©v√©nement :

- **Climatique** : Traceability et Company Data Alignment plus importants
- **R√©glementaire** : Source Relevance et Traceability critiques
- **G√©opolitique** : Strategic Alignment et Recommendation Appropriateness prioritaires

### 3. Confidence Score

Chaque crit√®re a un score de confiance (0-1) permettant de d√©tecter les √©valuations incertaines.

### 4. Explainability Renforc√©e

Pour chaque crit√®re :

- **Score** (0-10)
- **Confidence** (0-1)
- **Comment** (1-2 phrases)
- **Evidence** (liste de preuves)
- **Weaknesses** (liste de faiblesses)

### 5. D√©cision Automatique

| Score Global | Confiance | Action |
|--------------|-----------|--------|
| ‚â• 8.5 | ‚â• 0.85 | **APPROVE** (Alerte imm√©diate) |
| ‚â• 8.5 | < 0.85 | **REVIEW** (Validation humaine) |
| 7.0-8.4 | ‚â• 0.80 | **REVIEW** |
| 7.0-8.4 | < 0.80 | **REVIEW_PRIORITY** |
| < 7.0 | - | **REJECT** (Archiver) |

### 6. Feedback Loop

Syst√®me d'am√©lioration continue bas√© sur les validations humaines :

- Log des d√©saccords Judge vs Humain
- Analyse des patterns tous les 10 cas
- Ajustement automatique des seuils
- M√©triques de performance (cible: ‚â• 92% accuracy)

---

## üìÅ Structure des Fichiers

```

agent_3/
‚îú‚îÄ‚îÄ __init__.py                  # Exports du module
‚îú‚îÄ‚îÄ judge.py                     # Agent Judge principal (Anthropic)
‚îú‚îÄ‚îÄ criteria_evaluator.py        # √âvaluation des crit√®res avec Claude
‚îú‚îÄ‚îÄ weights_config.py            # Configuration des poids par type de risque
‚îú‚îÄ‚îÄ prompts.py                   # Prompts structur√©s pour Claude
‚îú‚îÄ‚îÄ feedback_loop.py             # Syst√®me d'am√©lioration continue
‚îú‚îÄ‚îÄ test_judge.py                # Tests avec donn√©es r√©elles
‚îî‚îÄ‚îÄ README.md                    # Cette documentation
```

---

## üöÄ Installation

### 1. Installer le SDK Anthropic

```bash
pip install anthropic
```

### 2. Copier les Fichiers

```bash
# Dans votre d√©p√¥t dataNova
cd backend/src

# Cr√©er le dossier agent_3
mkdir -p agent_3

# Copier tous les fichiers du package
cp /path/to/agent_3_anthropic/agent_3/* agent_3/
```

### 3. Configuration

Cr√©ez ou modifiez le fichier `.env` :

```bash
# API Key Anthropic
ANTHROPIC_API_KEY=sk-ant-api03-...

# (Optionnel) Pour Agent 2 si vous utilisez aussi OpenAI
OPENAI_API_KEY=your_openai_key_here
```

**Important** : Le SDK Anthropic cherche automatiquement `ANTHROPIC_API_KEY` dans les variables d'environnement.

---

## üß™ Tests

### Test Complet avec Donn√©es R√©elles

```bash
cd backend/src/agent_3

# Ex√©cuter le test
python test_judge.py
```

**R√©sultat attendu** :

```
================================================================================
üß™ TESTS AGENT 3 (JUDGE) - √âvaluation de Qualit√©
================================================================================

üìä Donn√©es charg√©es:
  - 8 sites
  - 10 fournisseurs
  - 10 relations
  - 3 documents

================================================================================
üß™ TEST : Inondations majeures √† Bangkok...
   Type: climatique
================================================================================

üîÑ √âtape 1 : Analyse d'Agent 2...

üìä R√©sultat Agent 2:
   - Sites impact√©s: 1
   - Fournisseurs impact√©s: 1
   - Niveau de risque: CRITIQUE
   - Recommandations: 9

üîÑ √âtape 2 : √âvaluation du Judge...

üéØ √âvaluation Judge pour document: doc_bangkok_flood
   Type d'√©v√©nement: climatique

üìã √âvaluation du Pertinence Checker...
   ‚úÖ Score pond√©r√©: 9.1/10
   ‚úÖ Confiance: 0.93

üìä √âvaluation du Risk Analyzer...
   ‚úÖ Score pond√©r√©: 8.4/10
   ‚úÖ Confiance: 0.88

üéØ Score global: 8.7/10
üéØ Confiance globale: 0.90

ü§î D√©termination de l'action...
   ‚úÖ Action: APPROVE
   üìù Raisonnement: Score global de 8.7 (> 8.5) avec confiance √©lev√©e (0.90)...

================================================================================
‚úÖ R√âSULTAT DE L'√âVALUATION JUDGE
================================================================================

üìã Pertinence Checker:
   Score pond√©r√©: 9.1/10
   Confiance: 0.93

üìä Risk Analyzer:
   Score pond√©r√©: 8.4/10
   Confiance: 0.88

üéØ Score Global: 8.7/10
üéØ Confiance Globale: 0.90

üö¶ D√©cision: APPROVE
üìù Raisonnement: Score global de 8.7 (> 8.5) avec confiance √©lev√©e (0.90)...

üíæ R√©sultat complet sauvegard√© dans: judge_result.json

================================================================================
‚úÖ TEST TERMIN√â
================================================================================
```

---

## üíª Utilisation Programmatique

### Exemple Simple

```python
from agent_3.judge import Judge

# Initialiser le Judge (utilise ANTHROPIC_API_KEY automatiquement)
judge = Judge(llm_model="claude-sonnet-4-20250514")

# √âvaluer une analyse
result = judge.evaluate(
    document=document_dict,
    pertinence_result=pertinence_result,
    risk_analysis=risk_analysis,
    sites=sites_list,
    suppliers=suppliers_list,
    supplier_relationships=relationships_list
)

# R√©cup√©rer la d√©cision
action = result['judge_evaluation']['action_recommended']
score = result['judge_evaluation']['overall_quality_score']
reasoning = result['judge_evaluation']['reasoning']

print(f"D√©cision: {action}")
print(f"Score: {score}/10")
print(f"Raisonnement: {reasoning}")
```

### Exemple avec Feedback Loop

```python
from agent_3.judge import Judge
from agent_3.feedback_loop import JudgeFeedbackLoop

judge = Judge()
feedback = JudgeFeedbackLoop()

# √âvaluer
result = judge.evaluate(...)
judge_decision = result['judge_evaluation']['action_recommended']
judge_score = result['judge_evaluation']['overall_quality_score']

# Validation humaine
human_decision = "APPROVE"  # D√©cision de l'humain
human_reasoning = "Analyse compl√®te et bien justifi√©e"

if judge_decision != human_decision:
    # Log du d√©saccord
    feedback.log_disagreement(
        case_id=document_id,
        judge_decision=judge_decision,
        human_decision=human_decision,
        human_reasoning=human_reasoning,
        judge_score=judge_score
    )
else:
    # Log de l'accord
    feedback.log_agreement(
        case_id=document_id,
        decision=judge_decision,
        score=judge_score
    )

# R√©cup√©rer les m√©triques
metrics = feedback.get_metrics()
print(f"Pr√©cision du Judge: {metrics['judge_accuracy'] * 100}%")
```

---

## üîß Mod√®les Claude Disponibles

Le SDK Anthropic supporte plusieurs mod√®les Claude :

- **`claude-sonnet-4-20250514`** (recommand√©) : Meilleur √©quilibre qualit√©/co√ªt
- **`claude-opus-4-20250514`** : Qualit√© maximale (plus co√ªteux)
- **`claude-haiku-4-20250514`** : Plus rapide et √©conomique

Pour changer de mod√®le :

```python
judge = Judge(llm_model="claude-opus-4-20250514")
```

---

## üìä Diff√©rences avec la Version OpenAI

| Aspect | Version Anthropic | Version OpenAI (Proxy) |
|--------|-------------------|------------------------|
| SDK | `anthropic` | `openai` |
| API Key | `ANTHROPIC_API_KEY` | `OPENAI_API_KEY` |
| Mod√®le | `claude-sonnet-4-20250514` | `claude-sonnet-4-5-20250929` |
| Appel API | `client.messages.create()` | `client.chat.completions.create()` |
| R√©ponse | `response.content[0].text` | `response.choices[0].message.content` |

---

## üêõ R√©solution de Probl√®mes

### Erreur : "ANTHROPIC_API_KEY not found"

```bash
# Cr√©er le fichier .env
echo "ANTHROPIC_API_KEY=sk-ant-api03-..." > backend/.env

# V√©rifier
cat backend/.env
```

### Erreur : "Module 'anthropic' not found"

```bash
# Installer le SDK
pip install anthropic

# V√©rifier
python -c "import anthropic; print(anthropic.__version__)"
```

### Scores trop bas ou trop √©lev√©s

Ajuster les poids dans `weights_config.py` ou utiliser le feedback loop pour calibrer automatiquement.

---

## üí∞ Co√ªts Estim√©s

**Avec Claude Sonnet 4** :
- ~2-3 appels API par √©valuation
- ~4000 tokens par appel (input + output)
- Co√ªt : ~$0.02-0.03 par √©valuation compl√®te

**Pour 1000 √©valuations/mois** : ~$20-30/mois

---

## üìù Notes Importantes

- **Mod√®le LLM** : Claude Sonnet 4 recommand√© pour la meilleure qualit√©
- **Performance** : ~10-15 secondes par √©valuation compl√®te
- **Pr√©cision cible** : ‚â• 92% d'accord avec les validations humaines
- **Rate Limits** : Respecter les limites de l'API Anthropic (v√©rifier votre tier)

---

**Cr√©√© le 31 janvier 2026 pour le projet PING (Hutchinson)**
**Version Anthropic Claude API**
