{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Cle API**"
      ],
      "metadata": {
        "id": "t0vj9ETyjBMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARaoqNMAhneW",
        "outputId": "e7db784d-0a35-441e-d745-3194c183f9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.47.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U langchain langchain-core langchain-community langgraph langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI (Gemini) API key: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2lGwLTFhqVo",
        "outputId": "94ae0d0b-170b-40e9-aa9b-9a7b00765c8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI (Gemini) API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",  # rapide/économique ; tu peux changer\n",
        "    temperature=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "XuZlTjDFiBbj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Donne-moi une phrase de 4 mots\").content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9IyHT3gqiLIU",
        "outputId": "b4b44ef0-cf05-445e-f234-03f69ae60c54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Le chat dort bien.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creation des outils**"
      ],
      "metadata": {
        "id": "ZaVa_CiNkDCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "import math\n",
        "\n",
        "@tool\n",
        "def calc(expression: str) -> str:\n",
        "    \"\"\"Évalue une expression mathématique simple. Ex: '2*(3+4)' ou 'sqrt(2)'.\"\"\"\n",
        "    allowed = {\"sqrt\": math.sqrt, \"pi\": math.pi, \"e\": math.e}\n",
        "    try:\n",
        "        # eval \"restreint\" : pas d'accès aux builtins\n",
        "        result = eval(expression, {\"__builtins__\": {}}, allowed)\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Erreur: {e}\"\n",
        "\n",
        "@tool\n",
        "def faq(produit: str) -> str:\n",
        "    \"\"\"Retourne des infos internes sur un produit (exemple).\"\"\"\n",
        "    base = {\n",
        "        \"alpha\": \"Alpha: abonnement mensuel, support email.\",\n",
        "        \"beta\": \"Beta: paiement à l'usage, support chat.\",\n",
        "    }\n",
        "    return base.get(produit.lower(), \"Je n'ai rien sur ce produit.\")\n"
      ],
      "metadata": {
        "id": "e9jqGlwokGka"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Construction de l'agent**"
      ],
      "metadata": {
        "id": "qnjl3_DkkXIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "tools = [calc, faq]\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=tools,\n",
        "    prompt=\"Tu es un assistant utile. Utilise les outils quand c'est pertinent.\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF3bTDmLkQqg",
        "outputId": "017e5cda-5055-4ca8-fd87-0493b92065a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1273727277.py:5: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  agent = create_react_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Premiere requete**"
      ],
      "metadata": {
        "id": "1UJ0dkAmkgxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"quelle est l'heure actuelle en france en 4 mots\"}]}\n",
        "\n",
        "result = agent.invoke(inputs)\n",
        "result[\"messages\"][-1].content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxkKK1t3kkmB",
        "outputId": "0088d930-3e1d-4034-e329-5a3445dabcd5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': \"Je ne peux pas vous donner l'heure.\",\n",
              "  'extras': {'signature': 'CoADAXLI2nzHsdhlE1fvD70V3i+fSwQQjk3JKMHe7/W2AbSEcolqXMIfXpNTK7DUkASEVkqvqhk87qwMiOUG4E5aH0lel7kCSJyr8O9TVIftlt2ZtW4WGjgMC2u9tq03W53G++O+CmNsvGBHjjBly/YxLl7lmRkV6XdVbL1SNYDYTvWSd/Y4FCc9Xl5HRx52aius9Zp69zSVAm2w0n9jZeaX87SsGHrR8ylmqv84CM9iIaSQCsZNGHLx/9cLZcJK+8IiXcE11IQWkEuAXUix2GBqXVxsBVE6KrrLnt06Dq1u63C05WnOFnzn0Qxr3eGlZ+7nAuzHBCImG/ZIn86j+rA4VPm8TLBrweDlUedHMW/849nIYuiNo74nH+BBCNr8WI5gvGWj8qkcx8JnsmVJIkL+rGGAoQTX+AXkDX1WEEXU+S1L3r0GKFIfQ6lFP7LTUM7R0SjTyQfs2q0ws7yqaF3ekuqVvlldDmnn+uDCL7arW5ot+MDBjd4fP6jCzrW49cSW'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **suivie de l'agent**"
      ],
      "metadata": {
        "id": "kXo-9uM6l3kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent.stream(inputs, stream_mode=\"updates\"):\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IEPbQS7ksZC",
        "outputId": "99b7ed54-caea-4706-d6d1-dbf140cbf566"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=[{'type': 'text', 'text': \"Je ne peux pas vous donner l'heure.\", 'extras': {'signature': 'CoADAXLI2nwEHNL/860FxsShLmvZqkWJtt+jvjvYH7bcmkQvtsaCrvxqcuq3pdberUb0OTpSRJA2Yvknxd5T3CxAdMtF1xcXVcMTFMnAHftiSimDt6FOHOJz61joSpPiMiCFdPQMHtdCnUTA6LeNGZBmTlmg6SzisVgHi1E1DfmLdxIEs1dP4LF6OIoNZJJ+QvFIvjVl9LwALtCqBWyfnUDUJPFPN4QqvJ3wKsUZLwP/Z6Fyc6pULhD9ABTScSKVi20ILmujnrzMmemdRAhi2HgteakeLo9OgwIJgws/e1JZaolTLZYhXsWpD3aRV/VHMmgv7KUsgKlqZKNFx5eBb77RgIX9ttFW8X+6YlInYg5mJ8+FF41L/kEHaPR0pwLifKTtBw1RSu3mxcp2paebuDQvUqagV6u+JHxyLGsuK52jbwBTUiLTKUW9lj7CxXACSd+GSXyOWDIeb/ev6Gv/4PeKzjZ1NUc8E3TlF6tAZOQana5Rgh3gLCovK2Y+2VgkjpAP'}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b98a6-8291-7203-9600-47a65db7bdea-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 126, 'output_tokens': 75, 'total_tokens': 201, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 65}})]}}\n"
          ]
        }
      ]
    }
  ]
}